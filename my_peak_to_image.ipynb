{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd069092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCN for binary image classifier (peak's existance or not)\n",
    "\n",
    "import scipy.io\n",
    "from scipy.sparse import coo_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sys import getsizeof\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from MyDataset import MyDataset\n",
    "import random\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f03cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "images = torch.load('images.pt')\n",
    "labels = torch.load('labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 1\n",
    "# Learning rate of optimizer\n",
    "learning_rate = 0.001\n",
    "# Batch size of data loaders and batch size used when training model\n",
    "batch_size = 16\n",
    "#dropout rate\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea010dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(images))\n",
    "print(len(labels))\n",
    "\n",
    "random.Random(10).shuffle(images) # shuffling with seed\n",
    "random.Random(10).shuffle(labels) \n",
    "\n",
    "images=images[100:600]\n",
    "labels=labels[100:600]\n",
    "\n",
    "size = len(images)\n",
    "\n",
    "dataset = MyDataset(images,labels)\n",
    "\n",
    "split_indices = list(range(0,size))\n",
    "\n",
    "train_idx=split_indices[0:round(0.70*size)]\n",
    "val_idx=split_indices[round(0.70*size):round(0.85*size)]\n",
    "test_idx=split_indices[round(0.85*size):]\n",
    "print(train_idx)\n",
    "print(val_idx)\n",
    "print(test_idx)\n",
    "\n",
    "train_dataset=MyDataset([images[i] for i in train_idx],[labels[i] for i in train_idx])\n",
    "val_dataset=MyDataset([images[i] for i in val_idx],[labels[i] for i in val_idx])\n",
    "test_dataset=MyDataset([images[i] for i in test_idx],[labels[i] for i in test_idx])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for data, target in train_loader:\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5bdc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layer (sees 13000x560x1 \"image\" tensor)\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3, padding=1)\n",
    "        self.conv1_bn=nn.BatchNorm2d(4)\n",
    "        # convolutional layer (sees 1625x140x4 tensor)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3, padding=1)\n",
    "        self.conv2_bn=nn.BatchNorm2d(8)\n",
    "        # convolutional layer (sees 203x35x8 tensor)\n",
    "        self.conv3 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.conv3_bn=nn.BatchNorm2d(16)\n",
    "        # max pooling layers\n",
    "        self.pool_1 = nn.MaxPool2d(2, [8,4])\n",
    "        #self.pool_2 = nn.MaxPool2d(2, [2,2])\n",
    "        # linear layer (X -> 10)\n",
    "        self.fc1 = nn.Linear(16 * 26 * 9, 10)\n",
    "        # linear layer (10 -> 1)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        #print(x.shape)\n",
    "        x = self.pool_1(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        #print(x.shape)\n",
    "        x = self.pool_1(F.relu(self.conv2_bn(self.conv2(x))))\n",
    "        #print(x.shape)\n",
    "        x = self.pool_1(F.relu(self.conv3_bn(self.conv3(x))))\n",
    "        #print(x.shape)\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 16 * 26 * 9)\n",
    "        #print(x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(x.shape)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # output\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = x.view(x.size(0))\n",
    "        #print(x.shape)    \n",
    "        return x          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe63555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a complete CNN\n",
    "torch.manual_seed(10) # set seed before creating model\n",
    "model = Net()\n",
    "        \n",
    "print(model.state_dict()['fc1.weight'])\n",
    "\n",
    "print(model)\n",
    "    \n",
    "# specify loss function (Binary cross entropy)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e24a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "#train_on_gpu = False\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "train_loss= [0.0] * n_epochs\n",
    "valid_loss= [0.0] * n_epochs\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    #train_loss[epoch] = 0.0\n",
    "    #valid_loss[epoch] = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        data=data.to_dense() # model needs dense matrices as input\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        output = output.to(torch.float64) #\n",
    "        target = target.to(torch.float64) #\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss[epoch] += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        data=data.to_dense() # model needs dense matrices as input\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        output = output.to(torch.float64) #\n",
    "        target = target.to(torch.float64) #\n",
    "        print(output)\n",
    "        print(target)\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss[epoch] += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss[epoch] = train_loss[epoch]/len(train_loader.sampler)\n",
    "    valid_loss[epoch] = valid_loss[epoch]/len(valid_loader.sampler)\n",
    "        \n",
    "    # print training/validation statistics\n",
    "    print_train_loss=train_loss[epoch]\n",
    "    print_valid_loss=valid_loss[epoch]\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, print_train_loss, print_valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss[epoch] <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        print_valid_loss))\n",
    "        torch.save(model.state_dict(), 'my_model.pt')\n",
    "        valid_loss_min = valid_loss[epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d0e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_dpi(200)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "line1 = plt.plot(np.linspace(1, n_epochs, num=n_epochs), train_loss)\n",
    "line2 = plt.plot(np.linspace(1, n_epochs, num=n_epochs), valid_loss)\n",
    "plt.legend([\"train loss\", \"valid loss\"])\n",
    "#plt.xticks(np.arange(0, n_epochs, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa014b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('my_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "#if train_on_gpu:\n",
    "#model.cuda()\n",
    "\n",
    "total = 0\n",
    "true_positive = 0\n",
    "true_negative = 0\n",
    "\n",
    "\n",
    "for data, target in test_loader:\n",
    "        data=data.to_dense() # model needs dense matrices as input\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        #if train_on_gpu:\n",
    "        #    data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        output = output.to(torch.float64) #\n",
    "        target = target.to(torch.float64) #\n",
    "        print(output)\n",
    "        print(target)\n",
    "        \n",
    "        for i in range(len(output)):\n",
    "            if (target[i] == 1) and (output[i] >= 0.5):\n",
    "                true_positive += 1\n",
    "            if (target[i] == 0) and (output[i] < 0.5):\n",
    "                true_negative += 1\n",
    "            total +=1\n",
    "            \n",
    "p_95 = proportion_confint((true_positive+true_negative), total, 0.05, 'normal')\n",
    "accuracy = (true_positive + true_negative)/total\n",
    "print('Accuracy:' + str(accuracy) + str(p_95))                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb39bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf90372c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e002a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab7706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e86dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4d7f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9d956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b9015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad037872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e33af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52abb718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ccfb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899af38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13464e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
